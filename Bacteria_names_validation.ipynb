{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ef4ecd",
   "metadata": {},
   "source": [
    "## Function to validate bacteria in both LSPN downloaded list and LPSN website (not validly published bacteria) through webscrapping\n",
    "\n",
    "Validate species names which is in abstract: extract_ab(text) function\n",
    "\n",
    "outputs from LLM can be validated using: validate_species_name() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c224dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pymongo\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "dblist = myclient.list_database_names()\n",
    "mydb = myclient[\"pathogens_filtered\"]\n",
    "mycol = mydb[\"pathogens_filtered_corrected\"]\n",
    "\n",
    "lspn = mydb[\"lspn_final_new\"]\n",
    "\n",
    "#mydb = myclient[\"pathogens_filtered\"]\n",
    "synonym_db = mydb[\"new_synonyms_new\"]\n",
    "\n",
    "with open(\"all_bacterias_de.txt\") as file:\n",
    "    allspecies_temp=file.readlines()\n",
    "    \n",
    "allspecies_de=[re.sub(\"[^a-zA-Z ]\",\"\",i).lower() for i in allspecies_temp]\n",
    "\n",
    "def find_species(name):\n",
    "    URL=\"\"\"https://lpsn.dsmz.de/species/\"\"\"\n",
    "    URL+=\"-\".join(name.split(\" \"))\n",
    "    #print(name)\n",
    "\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    species_elements = soup.find_all(\"title\")\n",
    "    for species_element in species_elements:\n",
    "            species_name = species_element.text.replace(\"Species: \",\"\").strip().lower()\n",
    "            return species_name\n",
    "\n",
    "        \n",
    "def validate_species_name(x, ws): \n",
    "    #print(x)\n",
    "    x=x.lower()\n",
    "    ignore_words=[\"it\",\"et\",\"isolates\",\"of\",\"species\", \"analyses\", \"data\",\"journal\",\"with\",\"and\",\"to\",\"strain\",\"on\",\"his\",\"her\", \"spp\" \"species\",\"the\", \"is\",\"were\",\"are\",\"we\",\"this\", \"he\", \"she\", \"sample\", \"in\", \"was\",\"from\"]\n",
    "    if x.split(\" \")[0] in ignore_words or x.split(\" \")[1] in ignore_words:\n",
    "        return 0\n",
    "    count=lspn.count_documents({\"bacteria name\":x} )\n",
    "    #print(count)\n",
    "    if count>0:\n",
    "        return x\n",
    "    else:\n",
    "        count=lspn.count_documents({\"bacteria synonym\":x} )\n",
    "        #print(count)\n",
    "        if count>0:\n",
    "            return x\n",
    "    # below uses webscrapping to validate names of non-validly published species.\n",
    "    if ws:\n",
    "        names=find_species(x)\n",
    "        if names==x:\n",
    "           #print(\"ws\")\n",
    "           return x\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def extract_func(text,ws, pattern_number):\n",
    "    bacteria_found=[]\n",
    "    # Regular expression pattern to match bacterial species\n",
    "    #pattern_1 = r'\\b[A-Z][a-z]+ [a-z]+\\b'\n",
    "    pattern_1 = r'\\b[A-Z][a-z]+ [A-Za-z]+\\b' # pattern for bacteria names Abc Abc / Abc abc\n",
    "    pattern_2 = r'\\b[A-Z][a-z]+ [(][A-Za-z]+[)]+ [A-Za-z]+\\b' # pattern for bacteria names Abc (abc) Abc \n",
    "    pattern_3= r'\\b[A-Z][.] [A-Za-z]+\\b' # pattern for bacteria names with A. Abc / A. abc\n",
    "    #query=\"et journal and of in to with on an\" # ignore other pattern like Name et. al. \n",
    "    text=re.sub(\"[^a-zA-Z0-9(). \"\"]\",\" \",text)\n",
    "    #print(text)\n",
    "    if pattern_number==1:\n",
    "        \n",
    "        bacterial_species = re.findall(pattern_1, text)\n",
    "        #print(bacterial_species)\n",
    "        for j in set(bacterial_species):\n",
    "            #print(j)  \n",
    "            x=validate_species_name(j.lower(),ws)\n",
    "            if x:\n",
    "                bacteria_found.append(x)\n",
    "        \n",
    "    if pattern_number==2:\n",
    "        new=set(re.findall(pattern_2, text))\n",
    "        #print(len(new))\n",
    "        if len(new)>0:\n",
    "            bacterial_species= [re.sub('[(][A-Za-z]+[)] ',\"\",i) for i in new]\n",
    "            #print(bacterial_species)\n",
    "            for j in bacterial_species:\n",
    "                #print(j) \n",
    "                x=validate_species_name(j.lower(),ws)\n",
    "                if x:\n",
    "                    bacteria_found.append(x)                \n",
    "                        \n",
    "    if pattern_number==3:   \n",
    "        bacterial_species = set(re.findall(pattern_3, text))\n",
    "        #print(bacterial_species)\n",
    "        for j in bacterial_species:\n",
    "            g_n= j.split(\". \")[0].lower()\n",
    "            s_n=j.split(\". \")[1].lower()\n",
    "            pattern_for_match=\"[^a-z]\"+ g_n+ \"[a-z]+ \"+s_n+ \"[^a-z]\"\n",
    "            #print(pattern_for_match)\n",
    "            #b_name_j=re.findall(pattern_for_match,str(allspecies_de))\n",
    "            #print(\"^\"+g_n+\"* \"+s_n)\n",
    "            result=lspn.find({ \"bacteria name\":{\"$regex\" : \"^\"+g_n+\".* \"+s_n+\"/\" } })\n",
    "\n",
    "            #print(result)\n",
    "            for m in result:\n",
    "                #print(m)\n",
    "                bacteria_found.append(re.sub('[^a-z ]',\"\", m['bacteria name']))   \n",
    "                \n",
    "            result=synonym_db.find({ \"bacteria synonym\":{\"$regex\" : \"^\"+g_n+\".* \"+s_n+\"/\"} })\n",
    "\n",
    "            #print(result)\n",
    "            for m in result:\n",
    "                #print(m)\n",
    "                bacteria_found.append(re.sub('[^a-z ]',\"\", m['bacteria synonym']))   \n",
    "            \n",
    "                \n",
    "    return bacteria_found\n",
    "\n",
    "#use ws=True if we need non-validly publised species as they are not found in LSPN downloaded CSV file.\n",
    "def extract_ab(text,ws):\n",
    "    text=str(text)\n",
    "    bacteria_found=[]\n",
    "    [bacteria_found.append(i) for i in extract_func(text,ws, pattern_number=1)] \n",
    "    [bacteria_found.append(i) for i in extract_func(text,ws, pattern_number=2)] \n",
    "    [bacteria_found.append(i) for i in extract_func(text,ws, pattern_number=3)] \n",
    "    return list(set(bacteria_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6348ce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abditibacterium utsteinense']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ab(\" ansba asidha;udh akjdb;aiuda  Corynebacterium dentalis A. utsteinense sdfsdg\",ws=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e7fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
